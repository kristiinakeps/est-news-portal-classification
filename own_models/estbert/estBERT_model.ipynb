{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "estBERT_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU64A1nypuN1"
      },
      "source": [
        "# EstBERT model for Estonian news portal classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n3SrZfwpqLX"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "from pathlib import Path\n",
        "import time\n",
        "import random\n",
        "import csv\n",
        "\n",
        "# Check if we are running on a CPU or GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66_SKJEir8HE",
        "outputId": "a43a6395-c7ae-4c35-9dbe-8e6e54fd21ae"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gD3Umm0sBGg"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification, AdamW, AutoConfig\n",
        "from transformers import AutoTokenizer, PreTrainedTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGUvaJUQsMxU"
      },
      "source": [
        "PAD = '[PAD]'\n",
        "PAD_ID = 0\n",
        "DATA_PATH = Path('data')\n",
        "MODEL_NAME = 'tartuNLP/EstBERT'\n",
        "OUTPUTS = 6\n",
        "\n",
        "batch_size = 16\n",
        "test_split = .2\n",
        "validation_split = .3\n",
        "shuffle_dataset = True\n",
        "random_seed = 42"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou3hM4EusZIl"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True, padding_side='right')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DcPeVyms_vr"
      },
      "source": [
        "class NewsDataSet(Dataset):\n",
        "    def __init__(self, pretrain_tokenizer, data_folder='.data', test=False):\n",
        "        self.tokenizer = pretrain_tokenizer\n",
        "        self.label_vocab =  {'elu24': 0, 'err': 1, 'paevaleht': 2, 'postimees': 3, 'telegram': 4, 'uued_uudised': 5}\n",
        "        self.delimiters =  {'elu24': ';', 'err': ',', 'paevaleht': ',', 'postimees': ';', 'telegram': ',', 'uued_uudised': ','}\n",
        "        self.contents_idx = {'elu24': 7, 'err': 5, 'paevaleht': 3, 'postimees': 6, 'telegram': 3, 'uued_uudised': 3}\n",
        "        self.max_len = 128\n",
        "\n",
        "        self.data_folder = data_folder\n",
        "            \n",
        "        self.data = []\n",
        "        \n",
        "        if self.data_folder.exists():\n",
        "            self.load()\n",
        "        else:\n",
        "            raise ValueError(\"Data path doesn't exist!\")\n",
        "        \n",
        "    def load(self):\n",
        "        for label in ['err', 'paevaleht', 'telegram', 'uued_uudised', 'elu24', 'postimees']:\n",
        "            print(f'Reading {label} articles...')\n",
        "            filename = label + '_samples.csv'\n",
        "            p = self.data_folder / filename\n",
        "            with open(p, 'r', encoding='utf-8') as f:\n",
        "                csv_reader = csv.reader(f, delimiter=self.delimiters[label])\n",
        "                next(csv_reader) # header\n",
        "                for row in csv_reader:\n",
        "                    try:\n",
        "                        row = next(csv_reader)\n",
        "                        contents = row[self.contents_idx[label]]\n",
        "                        if label in ['elu24', 'postimees']:\n",
        "                            contents = contents.replace('|', '\\n')\n",
        "                        text = self.tokenizer.encode(contents, add_special_tokens=True, max_length=self.max_len, padding='max_length', truncation=True, return_tensors='pt')\n",
        "                        attention_mask = text > 0 \n",
        "                        attention_mask = attention_mask.squeeze().to(torch.uint8)\n",
        "                        torch_label = torch.tensor(self.label_vocab[label], dtype=torch.long)\n",
        "\n",
        "                        self.data.append((text.squeeze(), attention_mask, torch_label))\n",
        "                    except:\n",
        "                        continue\n",
        "                \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx][0], self.data[idx][1], self.data[idx][2]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdhkexwjuN1b",
        "outputId": "509063a7-6453-4d93-d3f9-b8e8f523ac63"
      },
      "source": [
        "data = NewsDataSet(tokenizer, DATA_PATH)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading err articles...\n",
            "Reading paevaleht articles...\n",
            "Reading telegram articles...\n",
            "Reading uued_uudised articles...\n",
            "Reading elu24 articles...\n",
            "Reading postimees articles...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-7BYOVAuoPi",
        "outputId": "bd41363b-2b01-43b0-c428-7146a79b0dbf"
      },
      "source": [
        "data[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([    2,  1249,   570, 20355,  4882, 33451,  3452,   282, 30952,  2416,\n",
              "           636,  5715,  1433,    15, 30952, 49883, 39707,    93, 20887,    36,\n",
              "         20355, 49885,   555, 12327, 49886,  8707,   316,  2308,  1433,  3419,\n",
              "           240,    11,   409,    42, 24931, 37010, 14820, 34090,   128,    11,\n",
              "          3814,   227, 43071, 20887, 27361, 20514, 49923, 22049, 35166,    15,\n",
              "         20355, 49885, 20887,    36,  3710, 39478,    25,  3936,    15,   881,\n",
              "          5142, 30952,    11,    74,  1693,    42, 39399,    10,  4867,  1543,\n",
              "           416, 10171,    15,    95, 20355,   633, 33744,  1685,  3976,    53,\n",
              "          2645, 21366,    11,    74,   614, 12839,   930,   619,   416,  5679,\n",
              "            15,   480,  6698, 20558,  1796,   316,   221,  2928, 20355,   511,\n",
              "         22857,   470,  2378,  5993,  1699,    11,    82,   118, 20355, 16860,\n",
              "         49882,  2261,   339, 22857, 20887,  6955,   100,   619,   614, 20355,\n",
              "         49885,   638,  9479,    15,   523, 20577,   339,     3]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.uint8),\n",
              " tensor(1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdCSVcseuv6A"
      },
      "source": [
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(data)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(test_split * dataset_size))\n",
        "if shuffle_dataset:\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, test_indices = indices[split:], indices[:split]\n",
        "val_split = int(np.floor(validation_split * len(train_indices)))\n",
        "train_indices, val_indices = train_indices[val_split:], train_indices[:val_split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "test_sampler = SubsetRandomSampler(test_indices)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKsGtsrxu18V"
      },
      "source": [
        "train_loader = DataLoader(data, batch_size=batch_size, sampler=train_sampler) \n",
        "validation_loader = DataLoader(data, batch_size=batch_size, sampler=valid_sampler)\n",
        "test_loader = DataLoader(data, batch_size=batch_size, sampler=test_sampler)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mno9qb9au6H9"
      },
      "source": [
        "config = AutoConfig.from_pretrained(MODEL_NAME, num_labels=len(data.label_vocab), output_attentions=False, output_hidden_states=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6T4Lz2EvcJ1",
        "outputId": "7798e639-9254-4992-e4cb-57c379cbf186"
      },
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n",
        "model.to(device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at tartuNLP/EstBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tartuNLP/EstBERT and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(50000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMLlxngIvhAw",
        "outputId": "d34156c4-734e-4b3a-c5d9-4f878a435372"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The {} model has {:} different named parameters.\\n'.format(MODEL_NAME, len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "emb_params = [p for p in params if 'embeddings' in p[0]]\n",
        "for p in emb_params:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "first_transformer_params = [p for p in params if '.0.' in p[0]]\n",
        "for p in first_transformer_params:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "cls_params = [p for p in params if 'classifier' in p[0]]\n",
        "for p in cls_params:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tartuNLP/EstBERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (50000, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "classifier.weight                                           (6, 768)\n",
            "classifier.bias                                                 (6,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PluX5Rsmvrav"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
        "\n",
        "epochs = 3\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_loader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwH_iG90vvQg"
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6c9E1nKvyFn"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIWprzSxv0Ya",
        "outputId": "287fb078-a835-4104-9e83-8f55265e591b"
      },
      "source": [
        "# Taken from this tutorial: https://github.com/aniruddhachoudhury/BERT-Tutorials/blob/master/Blog%202/BERT_Fine_Tuning_Sentence_Classification.ipynb\n",
        "# The code was modified\n",
        "\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed)\n",
        "\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_loader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed_mins, elapsed_secs = epoch_time(t0, time.time())\n",
        "            \n",
        "            # Report progress.\n",
        "            print(f'  Batch {step:>5,}  of  {len(train_loader):>5,}.    Elapsed: {elapsed_mins:}m {elapsed_secs:}s.')\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification\n",
        "        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_loader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(f\"  Average training loss: {avg_train_loss:.2f}\")\n",
        "    print(\"  Training epcoh took: {:}m {:}s\".format(*epoch_time(t0, time.time())))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_loader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification\n",
        "            outputs = model(b_input_ids, b_input_mask)\n",
        "\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}m {:}s\".format(*epoch_time(t0, time.time())))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    105.    Elapsed: 12m 4s.\n",
            "  Batch    80  of    105.    Elapsed: 24m 16s.\n",
            "\n",
            "  Average training loss: 1.13\n",
            "  Training epcoh took: 31m 55s\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.68\n",
            "  Validation took: 4m 8s\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    105.    Elapsed: 12m 15s.\n",
            "  Batch    80  of    105.    Elapsed: 24m 29s.\n",
            "\n",
            "  Average training loss: 0.68\n",
            "  Training epcoh took: 32m 8s\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.74\n",
            "  Validation took: 4m 8s\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    105.    Elapsed: 12m 14s.\n",
            "  Batch    80  of    105.    Elapsed: 24m 28s.\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Training epcoh took: 32m 7s\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 4m 7s\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t2vvy4OwkjD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f01a152-2079-487f-abbc-a93860a36327"
      },
      "source": [
        "print(\"\")\n",
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "test_loss, test_accuracy = 0, 0\n",
        "nb_test_steps, nb_test_examples = 0, 0\n",
        "\n",
        "final_preds = []\n",
        "final_golds = []\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_loader:\n",
        "    \n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # Telling the model not to compute or store gradients, saving memory and\n",
        "    # speeding up validation\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # This will return the logits rather than the loss because we have\n",
        "        # not provided labels.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification\n",
        "        outputs = model(b_input_ids, b_input_mask)\n",
        "\n",
        "\n",
        "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "    # values prior to applying an activation function like the softmax.\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    # Calculate the accuracy for this batch of test sentences.\n",
        "    tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
        "    final_preds.extend(logits)\n",
        "    final_golds.extend(label_ids)\n",
        "    \n",
        "    # Accumulate the total accuracy.\n",
        "    test_accuracy += tmp_test_accuracy\n",
        "\n",
        "    # Track the number of batches\n",
        "    nb_test_steps += 1\n",
        "\n",
        "# Report the final accuracy for this test run.\n",
        "print(\"  Accuracy: {0:.2f}\".format(test_accuracy/nb_test_steps))\n",
        "print(\"  Testing took: {:}m {:}s\".format(*epoch_time(t0, time.time())))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running Testing...\n",
            "  Accuracy: 0.71\n",
            "  Testing took: 3m 34s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "owe1msic8KY8",
        "outputId": "fc782ba4-73b6-43b8-f40e-9e5f7677946f"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "vocab = {0: 'elu24', 1 : 'err', 2 : 'paevaleht', 3 : 'postimees', 4 : 'telegram', 5: 'uued_uudised'}\n",
        "\n",
        "preds = [vocab[i] for i in np.argmax(final_preds, axis=1).flatten().tolist()]\n",
        "golds = [vocab[i] for i in final_golds]\n",
        "\n",
        "labels = list(set(preds).union(set(golds)))\n",
        "\n",
        "cm = confusion_matrix(preds, golds, labels=labels)\n",
        "\n",
        "df_cm = pd.DataFrame(cm, labels, labels)\n",
        "plt.figure(figsize=(20, 10))\n",
        "sn.set(font_scale=1.4)\n",
        "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16})\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MZgzurRwlbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1414db-17c3-4d25-fea7-56b2abef719a"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/tokenizer_config.json',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/vocab.txt',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}