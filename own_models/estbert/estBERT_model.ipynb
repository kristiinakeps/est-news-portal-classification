{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "estBERT_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU64A1nypuN1"
      },
      "source": [
        "# EstBERT model for Estonian news portal classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n3SrZfwpqLX"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "from pathlib import Path\n",
        "import time\n",
        "import random\n",
        "import csv\n",
        "\n",
        "# Check if we are running on a CPU or GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66_SKJEir8HE",
        "outputId": "a43a6395-c7ae-4c35-9dbe-8e6e54fd21ae"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gD3Umm0sBGg"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification, AdamW, AutoConfig\n",
        "from transformers import AutoTokenizer, PreTrainedTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGUvaJUQsMxU"
      },
      "source": [
        "PAD = '[PAD]'\n",
        "PAD_ID = 0\n",
        "DATA_PATH = Path('data')\n",
        "MODEL_NAME = 'tartuNLP/EstBERT'\n",
        "OUTPUTS = 6\n",
        "\n",
        "batch_size = 16\n",
        "test_split = .2\n",
        "validation_split = .3\n",
        "shuffle_dataset = True\n",
        "random_seed = 42"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou3hM4EusZIl"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True, padding_side='right')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DcPeVyms_vr"
      },
      "source": [
        "class NewsDataSet(Dataset):\n",
        "    def __init__(self, pretrain_tokenizer, data_folder='.data', test=False):\n",
        "        self.tokenizer = pretrain_tokenizer\n",
        "        self.label_vocab =  {'elu24': 0, 'err': 1, 'paevaleht': 2, 'postimees': 3, 'telegram': 4, 'uued_uudised': 5}\n",
        "        self.delimiters =  {'elu24': ';', 'err': ',', 'paevaleht': ',', 'postimees': ';', 'telegram': ',', 'uued_uudised': ','}\n",
        "        self.contents_idx = {'elu24': 7, 'err': 5, 'paevaleht': 3, 'postimees': 6, 'telegram': 3, 'uued_uudised': 3}\n",
        "        self.max_len = 128\n",
        "\n",
        "        self.data_folder = data_folder\n",
        "            \n",
        "        self.data = []\n",
        "        \n",
        "        if self.data_folder.exists():\n",
        "            self.load()\n",
        "        else:\n",
        "            raise ValueError(\"Data path doesn't exist!\")\n",
        "        \n",
        "    def load(self):\n",
        "        for label in ['err', 'paevaleht', 'telegram', 'uued_uudised', 'elu24', 'postimees']:\n",
        "            print(f'Reading {label} articles...')\n",
        "            filename = label + '_samples.csv'\n",
        "            p = self.data_folder / filename\n",
        "            with open(p, 'r', encoding='utf-8') as f:\n",
        "                csv_reader = csv.reader(f, delimiter=self.delimiters[label])\n",
        "                next(csv_reader) # header\n",
        "                for row in csv_reader:\n",
        "                    try:\n",
        "                        row = next(csv_reader)\n",
        "                        contents = row[self.contents_idx[label]]\n",
        "                        if label in ['elu24', 'postimees']:\n",
        "                            contents = contents.replace('|', '\\n')\n",
        "                        text = self.tokenizer.encode(contents, add_special_tokens=True, max_length=self.max_len, padding='max_length', truncation=True, return_tensors='pt')\n",
        "                        attention_mask = text > 0 \n",
        "                        attention_mask = attention_mask.squeeze().to(torch.uint8)\n",
        "                        torch_label = torch.tensor(self.label_vocab[label], dtype=torch.long)\n",
        "\n",
        "                        self.data.append((text.squeeze(), attention_mask, torch_label))\n",
        "                    except:\n",
        "                        continue\n",
        "                \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx][0], self.data[idx][1], self.data[idx][2]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdhkexwjuN1b",
        "outputId": "509063a7-6453-4d93-d3f9-b8e8f523ac63"
      },
      "source": [
        "data = NewsDataSet(tokenizer, DATA_PATH)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading err articles...\n",
            "Reading paevaleht articles...\n",
            "Reading telegram articles...\n",
            "Reading uued_uudised articles...\n",
            "Reading elu24 articles...\n",
            "Reading postimees articles...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-7BYOVAuoPi",
        "outputId": "bd41363b-2b01-43b0-c428-7146a79b0dbf"
      },
      "source": [
        "data[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([    2,  1249,   570, 20355,  4882, 33451,  3452,   282, 30952,  2416,\n",
              "           636,  5715,  1433,    15, 30952, 49883, 39707,    93, 20887,    36,\n",
              "         20355, 49885,   555, 12327, 49886,  8707,   316,  2308,  1433,  3419,\n",
              "           240,    11,   409,    42, 24931, 37010, 14820, 34090,   128,    11,\n",
              "          3814,   227, 43071, 20887, 27361, 20514, 49923, 22049, 35166,    15,\n",
              "         20355, 49885, 20887,    36,  3710, 39478,    25,  3936,    15,   881,\n",
              "          5142, 30952,    11,    74,  1693,    42, 39399,    10,  4867,  1543,\n",
              "           416, 10171,    15,    95, 20355,   633, 33744,  1685,  3976,    53,\n",
              "          2645, 21366,    11,    74,   614, 12839,   930,   619,   416,  5679,\n",
              "            15,   480,  6698, 20558,  1796,   316,   221,  2928, 20355,   511,\n",
              "         22857,   470,  2378,  5993,  1699,    11,    82,   118, 20355, 16860,\n",
              "         49882,  2261,   339, 22857, 20887,  6955,   100,   619,   614, 20355,\n",
              "         49885,   638,  9479,    15,   523, 20577,   339,     3]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.uint8),\n",
              " tensor(1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdCSVcseuv6A"
      },
      "source": [
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(data)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(test_split * dataset_size))\n",
        "if shuffle_dataset:\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, test_indices = indices[split:], indices[:split]\n",
        "val_split = int(np.floor(validation_split * len(train_indices)))\n",
        "train_indices, val_indices = train_indices[val_split:], train_indices[:val_split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "test_sampler = SubsetRandomSampler(test_indices)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKsGtsrxu18V"
      },
      "source": [
        "train_loader = DataLoader(data, batch_size=batch_size, sampler=train_sampler) \n",
        "validation_loader = DataLoader(data, batch_size=batch_size, sampler=valid_sampler)\n",
        "test_loader = DataLoader(data, batch_size=batch_size, sampler=test_sampler)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mno9qb9au6H9"
      },
      "source": [
        "config = AutoConfig.from_pretrained(MODEL_NAME, num_labels=len(data.label_vocab), output_attentions=False, output_hidden_states=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6T4Lz2EvcJ1",
        "outputId": "7798e639-9254-4992-e4cb-57c379cbf186"
      },
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n",
        "model.to(device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at tartuNLP/EstBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tartuNLP/EstBERT and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(50000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMLlxngIvhAw",
        "outputId": "d34156c4-734e-4b3a-c5d9-4f878a435372"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The {} model has {:} different named parameters.\\n'.format(MODEL_NAME, len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "emb_params = [p for p in params if 'embeddings' in p[0]]\n",
        "for p in emb_params:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "first_transformer_params = [p for p in params if '.0.' in p[0]]\n",
        "for p in first_transformer_params:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "cls_params = [p for p in params if 'classifier' in p[0]]\n",
        "for p in cls_params:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tartuNLP/EstBERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (50000, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "classifier.weight                                           (6, 768)\n",
            "classifier.bias                                                 (6,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PluX5Rsmvrav"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
        "\n",
        "epochs = 3\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_loader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwH_iG90vvQg"
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6c9E1nKvyFn"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIWprzSxv0Ya",
        "outputId": "287fb078-a835-4104-9e83-8f55265e591b"
      },
      "source": [
        "# Taken from this tutorial: https://github.com/aniruddhachoudhury/BERT-Tutorials/blob/master/Blog%202/BERT_Fine_Tuning_Sentence_Classification.ipynb\n",
        "# The code was modified\n",
        "\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed)\n",
        "\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_loader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed_mins, elapsed_secs = epoch_time(t0, time.time())\n",
        "            \n",
        "            # Report progress.\n",
        "            print(f'  Batch {step:>5,}  of  {len(train_loader):>5,}.    Elapsed: {elapsed_mins:}m {elapsed_secs:}s.')\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification\n",
        "        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_loader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(f\"  Average training loss: {avg_train_loss:.2f}\")\n",
        "    print(\"  Training epcoh took: {:}m {:}s\".format(*epoch_time(t0, time.time())))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_loader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification\n",
        "            outputs = model(b_input_ids, b_input_mask)\n",
        "\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}m {:}s\".format(*epoch_time(t0, time.time())))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    105.    Elapsed: 12m 4s.\n",
            "  Batch    80  of    105.    Elapsed: 24m 16s.\n",
            "\n",
            "  Average training loss: 1.13\n",
            "  Training epcoh took: 31m 55s\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.68\n",
            "  Validation took: 4m 8s\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    105.    Elapsed: 12m 15s.\n",
            "  Batch    80  of    105.    Elapsed: 24m 29s.\n",
            "\n",
            "  Average training loss: 0.68\n",
            "  Training epcoh took: 32m 8s\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.74\n",
            "  Validation took: 4m 8s\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    105.    Elapsed: 12m 14s.\n",
            "  Batch    80  of    105.    Elapsed: 24m 28s.\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Training epcoh took: 32m 7s\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 4m 7s\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t2vvy4OwkjD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f01a152-2079-487f-abbc-a93860a36327"
      },
      "source": [
        "print(\"\")\n",
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "test_loss, test_accuracy = 0, 0\n",
        "nb_test_steps, nb_test_examples = 0, 0\n",
        "\n",
        "final_preds = []\n",
        "final_golds = []\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_loader:\n",
        "    \n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # Telling the model not to compute or store gradients, saving memory and\n",
        "    # speeding up validation\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # This will return the logits rather than the loss because we have\n",
        "        # not provided labels.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification\n",
        "        outputs = model(b_input_ids, b_input_mask)\n",
        "\n",
        "\n",
        "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "    # values prior to applying an activation function like the softmax.\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    # Calculate the accuracy for this batch of test sentences.\n",
        "    tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
        "    final_preds.extend(logits)\n",
        "    final_golds.extend(label_ids)\n",
        "    \n",
        "    # Accumulate the total accuracy.\n",
        "    test_accuracy += tmp_test_accuracy\n",
        "\n",
        "    # Track the number of batches\n",
        "    nb_test_steps += 1\n",
        "\n",
        "# Report the final accuracy for this test run.\n",
        "print(\"  Accuracy: {0:.2f}\".format(test_accuracy/nb_test_steps))\n",
        "print(\"  Testing took: {:}m {:}s\".format(*epoch_time(t0, time.time())))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running Testing...\n",
            "  Accuracy: 0.71\n",
            "  Testing took: 3m 34s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "owe1msic8KY8",
        "outputId": "c812cc80-14a8-41a8-a5d6-ebc300f32bc9"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "vocab = {0: 'elu24', 1 : 'err', 2 : 'paevaleht', 3 : 'postimees', 4 : 'telegram', 5: 'uued_uudised'}\n",
        "\n",
        "preds = np.argmax(final_preds, axis=1).flatten().tolist()\n",
        "golds = final_golds\n",
        "\n",
        "labels = list(set(preds).union(set(golds)))\n",
        "\n",
        "cm = confusion_matrix(preds, golds, labels=labels)\n",
        "\n",
        "df_cm = pd.DataFrame(cm, labels, labels)\n",
        "plt.figure(figsize=(20, 10))\n",
        "sn.set(font_scale=1.4)\n",
        "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16})\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MZgzurRwlbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1414db-17c3-4d25-fea7-56b2abef719a"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/tokenizer_config.json',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/vocab.txt',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}